"""Abstract base class for FluidGym environments."""

import logging
from abc import ABC, abstractmethod
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Any, NamedTuple

import numpy as np
import pandas as pd
import seaborn as sns
import torch
from gymnasium import spaces

from fluidgym.config import config as fluidgym_config
from fluidgym.simulation.extensions import (
    PISOtorch,  # type: ignore[import-untyped,import-not-found]
)
from fluidgym.simulation.pict.util.domain_io import load_domain, save_domain
from fluidgym.simulation.pict.util.output import _resample_block_data, plot_grids
from fluidgym.simulation.simulation import Simulation
from fluidgym.types import EnvMode, FluidEnvLike
from fluidgym.util.data_utils import (
    load_statistics,
    load_uncontrolled_episode,
    prepare_initial_domains,
    save_statistics,
    save_uncontrolled_episode,
)


class Stats(NamedTuple):
    """Statistical summary of a quantity."""

    mean: float
    min: float
    max: float
    p5: float
    p25: float
    p50: float
    p75: float
    p95: float


@dataclass
class EnvState:
    """Dataclass to hold the state of a FluidEnv environment."""

    class_name: str
    domain: PISOtorch.Domain
    n_steps: int
    mode: EnvMode
    additional_info: dict[str, Any]


# Number of domains per mode
N_INITIAL_DOMAINS = 10

# Seeds used when the simulation needs to be restarted for every domain
MODE_SEEDS = [100, 200, 300]


class FluidEnv(ABC, FluidEnvLike):
    """Abstract base class for FluidGym environments.

    It provides common functionality for all FluidGym environments,
    such as managing the simulation, rendering, and saving/loading initial domains.

    Raises
    ------
    RuntimeError
        If CUDA is not available.

    ValueError
        If ndims is not 2 or 3.

    Notes
    -----
    The environment must be reset before calling step().
    The initial domain must be generated by calling init() before using the environment
    for training or evaluation.
    The initial domain is saved to disk when init() is called, and loaded when reset()
    is called.
    """

    metadata = {"render_modes": ["rbg_array"], "render_fps": 24}

    _default_render_key: str

    _ndims: int
    _supports_marl: bool = False

    _domain: PISOtorch.Domain
    _prep_fn: dict[str, Any]
    _sim: Simulation
    _dtype: torch.dtype
    _cuda_device: torch.device
    _cpu_device: torch.device
    _differentiable: bool

    _seed: int | None = None

    _reset_called: bool = False
    _n_episodes: int = 0
    _n_steps: int = 0
    _auto_render: bool
    __load_domain_on_reset: bool
    _step_length: float
    _dt: float

    # PRNGs
    _torch_rng_cuda: torch.Generator
    _torch_rng_cpu: torch.Generator
    _np_rng: np.random.Generator

    # How long the simulation needs to be run
    # to reach a steady state before starting RL
    _initial_domain_steps: int

    # Whether the simulations needs to be
    # restarted for every domain
    _initial_domain_restart: bool

    __frames: dict[str, list] = defaultdict(list)

    _mode: EnvMode = EnvMode.TRAIN

    _metrics: list[str]
    _metrics_stats: dict[str, Stats] = {}
    _velocity_stats: Stats | None = None
    _pressure_stats: Stats | None = None

    # DataFrame containing uncontrolled episode metrics
    # for the currently loaded (non-randomized) initial domain.
    _uncontrolled_episode: pd.DataFrame | None = None

    def __init__(
        self,
        adaptive_cfl: float,
        dt: float,
        step_length: float,
        episode_length: int,
        ndims: int,
        use_marl: bool,
        dtype: torch.dtype = torch.float32,
        cuda_device: torch.device | None = None,
        cpu_device: torch.device | None = None,
        auto_render: bool = False,
        load_initial_domain: bool = True,
        load_domain_statistics: bool = True,
        randomize_initial_state: bool = True,
        enable_actions: bool = True,
        differentiable: bool = False,
    ):
        """Initialize the FluidEnv.

        Parameters
        ----------
        adaptive_cfl: float
            Target CFL number for adaptive time stepping.

        dt: float
            The simulation time step.

        step_length: float
            The length of each environment step in non-dimensional time units.

        episode_length: int
            The number of steps per episode.

        ndims: int
            The number of spatial dimensions (2 or 3).

        use_marl: bool
            Whether to use multi-agent reinforcement learning (MARL) mode. If False,
            single-agent reinforcement learning (SARL) mode is used.

        dtype: torch.dtype
            The data type for the simulation (torch.float32 or torch.float64). Defaults
            to torch.float32.

        cuda_device: torch.device | None
            The CUDA device to use for the simulation. If None, the default CUDA device
            is used. Defaults to None.

        cpu_device: torch.device
            The CPU device to use for the simulation. If None, the default CPU device is
            used. Defaults to None.

        auto_render: bool
            Whether to automatically render and save a GIF at the end of each episode.
            Defaults to False.

        load_initial_domain: bool
            Whether to load the initial domain from disk. If False, a new domain will be
            created. Defaults to True.

        randomize_initial_state: bool
            Whether to randomize the initial state of the environment after loading or
            creating the domain. Defaults to False.

        enable_actions: bool
            Whether to enable actions. This should be False when generating initial
            domains. Defaults to True.

        differentiable: bool
            Whether to enable differentiable simulation. Defaults to False.
        """
        super().__init__()

        if not torch.cuda.is_available():
            raise RuntimeError("CUDA is not available. FluidGym requires a CUDA GPU.")

        if ndims not in [2, 3]:
            raise ValueError("ndims must be 2 or 3.")
        self._ndims = ndims

        self._dt = dt
        self._adaptive_cfl = adaptive_cfl
        self._step_length = step_length
        self._episode_length = episode_length

        self._use_marl = use_marl
        if self._use_marl and not self._supports_marl:
            raise ValueError("This env does not support multi-agent mode.")

        self._cuda_device = torch.device("cuda") if cuda_device is None else cuda_device
        self._cpu_device = torch.device("cpu") if cpu_device is None else cpu_device
        self._dtype = dtype
        self._auto_render = auto_render
        self.__load_domain_on_reset = load_initial_domain
        self._randomize_initial_state = randomize_initial_state
        self._enable_actions = enable_actions
        self._differentiable = differentiable

        if load_initial_domain or load_domain_statistics:
            prepare_initial_domains(initial_domain_id=self.initial_domain_id)

        if load_domain_statistics:
            self._load_domain_statistics()
        else:
            self._logger.warning(
                "Domain statistics not loaded. Some environment features may be "
                "unavailable. Only use this option for debugging or development "
                "purposes."
            )

        self._action_space = self._get_action_space()
        self._observation_space = self._get_observation_space()

        if self._use_marl:
            action_shape = (self.n_agents, *self.action_space.shape)
        else:
            action_shape = self.action_space.shape
        self._zero_action = torch.zeros(
            action_shape, device=self._cuda_device, requires_grad=False
        )

    @abstractmethod
    def _get_action_space(self) -> spaces.Box:
        """Per-agent action space."""
        raise NotImplementedError

    @abstractmethod
    def _get_observation_space(self) -> spaces.Dict:
        """Per-agent observation space."""
        raise NotImplementedError

    @property
    def _logger(self) -> logging.Logger:
        """Logger for the environment."""
        return logging.getLogger(self.__class__.__name__)

    @property
    def use_marl(self) -> bool:
        """Whether the environment is in multi-agent reinforcement learning mode."""
        return self._use_marl

    @property
    @abstractmethod
    def n_agents(self) -> int:
        """The number of agents in the environment."""
        raise NotImplementedError

    @property
    def step_length(self) -> float:
        """The length of each environment step in non-dimensional time units."""
        return self._step_length

    @property
    def episode_length(self) -> int:
        """The number of steps per episode."""
        return self._episode_length

    @property
    def dt(self) -> float:
        """The simulation time step."""
        return self._dt

    @property
    def ndims(self) -> int:
        """The number of spatial dimensions (2 or 3)."""
        return self._ndims

    @property
    @abstractmethod
    def render_shape(self) -> tuple[int, ...]:
        """The shape of the rendered domain."""
        raise NotImplementedError

    @property
    def metrics(self) -> list[str]:
        """The list of metrics tracked by the environment."""
        return self._metrics

    @property
    def time_passed(self) -> float:
        """The total time passed in the current episode."""
        return self._n_steps * self._step_length

    @property
    def n_sim_steps(self) -> int:
        """The number of simulation steps per environment step."""
        return self._n_sim_steps

    @property
    def mode(self) -> EnvMode:
        """The current mode of the environment ('train', 'val', or 'test')."""
        return self._mode

    @mode.setter
    def mode(self, mode: EnvMode) -> None:
        if mode not in [EnvMode.TRAIN, EnvMode.VAL, EnvMode.TEST]:
            raise ValueError("mode must be 'train', 'val', or 'test'.")
        self._mode = mode

    @property
    def cuda_device(self) -> torch.device:
        """The CUDA device used by the environment."""
        return self._cuda_device

    @property
    def differentiable(self) -> bool:
        """Whether the environment is differentiable."""
        return self._differentiable

    def train(self) -> None:
        """Set the environment to training mode."""
        self.mode = EnvMode.TRAIN

    def val(self) -> None:
        """Set the environment to evaluation mode."""
        self.mode = EnvMode.VAL

    def test(self) -> None:
        """Set the environment to test mode."""
        self.mode = EnvMode.TEST

    def sample_action(self) -> torch.Tensor:
        """Sample a random action uniformly from the action space.

        Returns
        -------
        torch.Tensor
            A random action.
        """
        if not isinstance(self.action_space, spaces.Box):
            raise TypeError("Only implemented for Box.")

        if self._seed is None:
            raise RuntimeError("Environment must be seeded before sampling actions.")

        low = torch.as_tensor(self.action_space.low, device=self._cuda_device)
        high = torch.as_tensor(self.action_space.high, device=self._cuda_device)
        r = torch.rand(
            self._zero_action.shape,
            device=self._cuda_device,
            generator=self._torch_rng_cuda,
        )
        return low + (high - low) * r

    @abstractmethod
    def _get_domain(self) -> PISOtorch.Domain:
        """Create and return the initial domain for the simulation.

        Returns
        -------
        PISOtorch.Domain
            The initial domain for the simulation.
        """
        raise NotImplementedError

    @abstractmethod
    def _get_prep_fn(self, domain: PISOtorch.Domain) -> dict[str, Any]:
        """Get the preparation function for the simulation.

        Parameters
        ----------
        domain: PISOtorch.Domain
            The domain for which to get the preparation function.

        Returns
        -------
        dict[str, Any]
            A dictionary containing the preparation functions.
        """
        raise NotImplementedError

    @abstractmethod
    def _get_simulation(
        self,
        domain: PISOtorch.Domain,
        prep_fn: dict[str, Any],
    ) -> Simulation:
        """Create and return the simulation object.

        Parameters
        ----------
        domain: PISOtorch.Domain
            The domain for the simulation.

        prep_fn: dict[str, Any]
            The preparation functions for the simulation.

        Returns
        -------
        Simulation
            The simulation object.
        """
        raise NotImplementedError

    def _additional_initialization(self) -> None:
        """Perform any additional initialization after the domain and simulation are
        created.
        """
        raise NotImplementedError

    @abstractmethod
    def _apply_action(self, action: torch.Tensor) -> None:
        """Apply the given action to the simulation.

        Parameters
        ----------
        action: torch.Tensor
            The action to apply.
        """
        raise NotImplementedError

    @abstractmethod
    def _get_global_obs(self) -> dict[str, torch.Tensor]:
        """Return the current global observation.

        Returns
        -------
        dict[str, torch.Tensor]
            The current observation.
        """
        raise NotImplementedError

    def _get_local_obs(self) -> dict[str, torch.Tensor]:
        """Return the current local agent observations.

        Returns
        -------
        dict[str, torch.Tensor]
            The current local agent observations.
        """
        raise NotImplementedError

    @abstractmethod
    def _randomize_domain(self) -> None:
        """Randomize the current domain of the environment."""
        raise NotImplementedError

    def _check_initial_domains_exists(
        self, mode: EnvMode | None = None, idx: int | None = None
    ) -> bool:
        """Check if the initial domain exists on disk.

        Parameters
        ----------
        mode: EnvMode | None
            Environment mode (e.g., 'train', 'val', 'test'). If None, checks for all
            tags. Defaults to None.

        idx: int | None
            Index of the initial domain to check. If None, checks for all indices.
              to None.

        Returns
        -------
        bool
            True if the initial domain exists, False otherwise.
        """
        modes = [EnvMode.TRAIN, EnvMode.VAL, EnvMode.TEST] if mode is None else [mode]
        idxs = range(N_INITIAL_DOMAINS) if idx is None else [idx]

        try:
            for _idx in idxs:
                for _mode in modes:
                    self.__load_initial_domain(mode=_mode, idx=_idx)
            return True
        except FileNotFoundError:
            return False

    def _set_initial_state(self, randomize: bool | None = None) -> None:
        """Set the initial state of the environment.

        Parameters
        ----------
        randomize: bool | None
            Whether to randomize the initial state. If None, the default behavior is
            used.
        """
        if self.__load_domain_on_reset:
            try:
                idx = (
                    int(self._np_rng.integers(0, N_INITIAL_DOMAINS)) if randomize else 0
                )
                self._domain = self.__load_initial_domain(mode=self.mode, idx=idx)
                try:
                    self._uncontrolled_episode = self._load_uncontrolled_episode(
                        idx=idx, mode=self.mode
                    )
                except FileNotFoundError:
                    self._logger.warning(
                        "Uncontrolled episode data not found for domain %d in mode %s.",
                        idx,
                        self.mode.value,
                    )
                    self._uncontrolled_episode = None
            except FileNotFoundError as err:
                raise RuntimeError(
                    "Initial domain not found. Please ensure it was downloaded."
                ) from err
        else:
            self._domain = self._get_domain()

        prep_fn = self._get_prep_fn(self._domain)
        self._sim = self._get_simulation(self._domain, prep_fn)

        # Some envs may need additional initialization
        self._additional_initialization()

        if randomize is None:
            randomize = self._randomize_initial_state

        if randomize:
            with torch.no_grad():
                self._randomize_domain()

    @abstractmethod
    def _get_render_data(
        self,
        render_3d: bool,
        output_path: Path | None = None,
    ) -> dict[str, np.ndarray]:
        """Return data required for rendering.

        Parameters
        ----------
        render_3d: bool
            Whether to enable 3d rendering.

        output_path: Path | None
            The output path to save the rendered files. If None, saves to the current
            directory. Defaults to None.

        Returns
        -------
        dict[str, np.ndarray]
            A dictionary mapping slices to data arrays for rendering.
        """
        raise NotImplementedError

    def __get_vorticity_2d(self) -> torch.Tensor:
        vorticity_blocks = []
        self._domain.UpdateDomainData()
        gradients = PISOtorch.ComputeSpatialVelocityGradients(self._domain)

        for block_id in range(len(gradients)):
            d_dx, d_dy = gradients[block_id]

            du_dy = d_dy[:, 0, :, :]
            dv_dx = d_dx[:, 1, :, :]

            vorticity_block = dv_dx - du_dy
            vorticity_block = vorticity_block[None, ...]

            vorticity_blocks += [vorticity_block]

        global_vorticity = _resample_block_data(
            data_list=vorticity_blocks,
            vertex_coord_list=self._sim.output_resampling_coords,
            resampling_out_shape=self._sim.output_resampling_shape,
            ndims=self._ndims,
            fill_max_steps=self._sim.output_resampling_fill_max_steps,
        )

        return global_vorticity

    def __get_vorticity_3d(self) -> torch.Tensor:
        vorticity_blocks = []
        self._domain.UpdateDomainData()
        gradients = PISOtorch.ComputeSpatialVelocityGradients(self._domain)

        for block_id in range(len(gradients)):
            d_dx, d_dy, d_dz = gradients[block_id]

            du_dy = d_dy[:, 0, :, :]
            dv_dx = d_dx[:, 1, :, :]

            dw_dx = d_dx[:, 2, :, :]
            du_dz = d_dz[:, 0, :, :]

            dv_dz = d_dz[:, 1, :, :]
            dw_dy = d_dy[:, 2, :, :]

            vorticity_block = torch.stack(
                [
                    dw_dy - dv_dz,
                    du_dz - dw_dx,
                    dv_dx - du_dy,
                ],
                dim=0,
            )

            vorticity_block = vorticity_block.squeeze(1).unsqueeze(0)

            vorticity_blocks += [vorticity_block]

        global_vorticity = _resample_block_data(
            data_list=vorticity_blocks,
            vertex_coord_list=self._sim.output_resampling_coords,
            resampling_out_shape=self._sim.output_resampling_shape,
            ndims=self._ndims,
            fill_max_steps=self._sim.output_resampling_fill_max_steps,
        )

        return global_vorticity

    def get_vorticity(
        self,
    ) -> torch.Tensor:
        """Get the vorticity field of the fluid.

        Returns
        -------
        torch.Tensor
            The vorticity field as a tensor.
        """
        if self._ndims == 2:
            return self.__get_vorticity_2d().squeeze()
        else:
            return self.__get_vorticity_3d().squeeze()

    def get_velocity(
        self,
    ) -> torch.Tensor:
        """Get the velocity field of the fluid.

        Returns
        -------
        torch.Tensor
            The velocity field as a tensor.
        """
        ndims = self._domain.getSpatialDims()
        blocks = self._domain.getBlocks()

        u_list = [block.velocity for block in blocks]
        u = _resample_block_data(
            data_list=u_list,
            vertex_coord_list=self._sim.output_resampling_coords,
            resampling_out_shape=self._sim.output_resampling_shape,
            ndims=ndims,
            fill_max_steps=self._sim.output_resampling_fill_max_steps,
        )

        return u.squeeze()

    def get_pressure(
        self,
    ) -> torch.Tensor:
        """Get the pressure field of the fluid.

        Returns
        -------
        torch.Tensor
            The pressure field as a tensor of shape (1, NDIM, H, W) for 2D or (1, NDIM,
            H, W, D) for 3D.
        """
        ndims = self._domain.getSpatialDims()
        blocks = self._domain.getBlocks()

        u_list = [block.pressure for block in blocks]

        u = _resample_block_data(
            data_list=u_list,
            vertex_coord_list=self._sim.output_resampling_coords,
            resampling_out_shape=self._sim.output_resampling_shape,
            ndims=ndims,
            fill_max_steps=self._sim.output_resampling_fill_max_steps,
        )

        return u.squeeze()

    @staticmethod
    def _format_render_data(
        data: np.ndarray,
        v_min: float | None = None,
        v_max: float | None = None,
        cmap: str = "viridis",
    ) -> np.ndarray:
        """Format data for rendering.
        This method normalizes the data and applies a colormap.

        Parameters
        ----------
        data: np.ndarray
            The data to be formatted.

        v_min: float | None
            The minimum value for normalization. If None, the minimum of the data is
            used.

        v_max: float | None
            The maximum value for normalization. If None, the maximum of the data is
            used.

        cmap: str
            The colormap to be applied.

        Returns
        -------
        np.ndarray
            The formatted data ready for rendering.
        """
        _v_min = np.min(data) if v_min is None else v_min
        _v_max = np.max(data) if v_max is None else v_max

        data = np.flip(data, axis=1)
        data = (data - _v_min) / (_v_max - _v_min)
        data = np.clip(data, 0.0, 1.0)
        return sns.color_palette(cmap, as_cmap=True)(data, bytes=True)[:, :, :3]

    def step(
        self, action: torch.Tensor
    ) -> tuple[
        dict[str, torch.Tensor], torch.Tensor, bool, bool, dict[str, torch.Tensor]
    ]:
        """Run one timestep of the environment's dynamics using the agent actions.

        When the end of an episode is reached (``terminated or truncated``), it is
        necessary to call :meth:`reset` to reset this environment's state for the next
        episode.

        Parameters
        ----------
        action: torch.Tensor
            The action to take.

        Returns
        -------
        tuple[
        dict[str, torch.Tensor], torch.Tensor, bool, bool, dict[str, torch.Tensor]]
            A tuple containing the observation, reward, terminated flag, truncated flag,
            and info dictionary.
        """
        if not self._reset_called:
            raise RuntimeError(
                "Environment must be reset before stepping. Call 'reset()' before"
                "'step()'."
            )

        if not action.shape == self._zero_action.shape:
            raise ValueError(
                f"Action shape {action.shape} does not match expected shape "
                f"{self._zero_action.shape}."
            )

        if self._use_marl:
            obs, reward, terminated, info = self._step_marl_impl(action)
        else:
            obs, reward, terminated, info = self._step_impl(action)

        self._n_steps += 1
        truncated = self._n_steps >= self._episode_length

        if self._auto_render:
            self.render()

        info = {k: v.detach() for k, v in info.items()}

        return obs, reward, terminated, truncated, info

    @abstractmethod
    def _step_impl(
        self, action: torch.Tensor
    ) -> tuple[dict[str, torch.Tensor], torch.Tensor, bool, dict[str, torch.Tensor]]:
        """Implementation of the step logic specific to the environment.

        Parameters
        ----------
        action: torch.Tensor
            The action to take.

        Returns
        -------
        tuple[dict[str, torch.Tensor], torch.Tensor, bool, dict[str, torch.Tensor]]
            A tuple containing the observation, reward, terminated flag, and info
            dictionary.
        """
        raise NotImplementedError

    def _step_marl_impl(
        self, action: torch.Tensor
    ) -> tuple[dict[str, torch.Tensor], torch.Tensor, bool, dict[str, torch.Tensor]]:
        """Implementation of the multi-agent step logic specific to the environment.

        Parameters
        ----------
        action: torch.Tensor
            The individual agent actions.

        Returns
        -------
        tuple[dict[str, torch.Tensor], torch.Tensor, bool, dict[str, torch.Tensor]]
            A tuple containing the local observations, local rewards, a global
            terminated flag, and a global info dictionary.
        """
        raise NotImplementedError

    @property
    def _n_sim_steps(self) -> int:
        """The number of simulation steps per environment step."""
        return max(1, int(self._step_length / self._dt))

    def seed(self, seed: int) -> None:
        """Update the random seeds and seed the random number generators.

        Parameters
        ----------
        seed: int
            The seed to set. If None, the current seed is used.
        """
        if seed is None:
            raise ValueError("Seed cannot be None.")

        self._seed = seed
        self._torch_rng_cuda = torch.Generator(device=self._cuda_device).manual_seed(
            seed
        )
        self._torch_rng_cpu = torch.Generator(device=self._cpu_device).manual_seed(seed)
        self._np_rng = np.random.default_rng(seed)

    def reset(
        self,
        seed: int | None = None,
        randomize: bool | None = None,
    ) -> tuple[dict[str, torch.Tensor], dict[str, torch.Tensor]]:
        """Resets the environment to an initial internal state, returning an initial
        observation and info.

        Parameters
        ----------
        seed: int | None
            The seed to use for random number generation. If None, the current seed is
            used.

        randomize: bool | None
            Whether to randomize the initial state. If None, the default behavior is
            used.

        Returns
        -------
        tuple[dict[str, torch.Tensor], dict[str, torch.Tensor]]
            A tuple containing the initial observation and an info dictionary.
        """
        if self._auto_render and len(self.__frames) > 0:
            self.save_gif(filename=f"episode_{self._n_episodes}")

        self.__frames = defaultdict(list)

        # First, we update the random seed as it may affect the initial state
        if seed is None:
            if self._seed is None:
                raise ValueError(
                    "Seed must be provided either during reset or by calling seed()."
                )
        else:
            self.seed(seed)

        # Then, we re-initialize the environment
        self._set_initial_state(randomize=randomize)

        self._reset_called = True
        self._n_steps = 0
        self._n_episodes += 1

        self._apply_action(self._zero_action)

        if self._use_marl:
            obs = self._get_local_obs()
        else:
            obs = self._get_global_obs()

        info: dict[str, torch.Tensor] = {}
        return obs, info

    def render(
        self,
        save: bool = False,
        render_3d: bool = False,
        filename: str | None = None,
        output_path: Path | None = None,
    ) -> np.ndarray:
        """Render the current state of the environment.

        Parameters
        ----------
        save: bool
            Whether to save the rendered frame as a PNG file. Defaults to False.

        render_3d: bool
            Whether to enable 3d rendering. Defaults to False.

        filename: str | None
            The filename to save the GIF file. If None, a default name is used.
            Defaults to None.

        output_path: Path | None
            The output path to save the rendered files. If None, saves to the current
            directory. Defaults to None.

        Returns
        -------
        np.ndarray
            The rendered frame as a numpy array.
        """
        from PIL import Image

        output_path = output_path or Path(".")
        output_path.mkdir(parents=True, exist_ok=True)

        render_data = self._get_render_data(
            render_3d=render_3d,
            output_path=output_path if save else None,
        )

        for slice_name, data in render_data.items():
            img = Image.fromarray(data)

            self.__frames[slice_name] += [img]

            if save:
                if filename is not None:
                    img.save(output_path / f"{slice_name}_{filename}.png")
                else:
                    img.save(
                        output_path
                        / f"{slice_name}_{self._n_episodes}_{self._n_steps}.png"
                    )

        if self._default_render_key in render_data:
            return render_data[self._default_render_key]
        else:
            # Return the first slice's data as a numpy array
            return next(iter(render_data.values()))

    def save_gif(self, filename: str, output_path: Path | None = None) -> None:
        """Save the rendered frames as a GIF file.

        Parameters
        ----------
        filename: str
            The filename for the GIF file.

        output_path: Path | None
            The output path to save the GIF file. If None, saves to the current
            directory. Defaults to None.
        """
        if output_path is None:
            output_path = Path(".")

        if len(self.__frames) == 0:
            raise ValueError("No frames to render GIF. Call render() first.")

        filename += ".gif" if not filename.endswith(".gif") else ""

        for slice_name, frames in self.__frames.items():
            fps = self.metadata["render_fps"]
            assert isinstance(fps, int)

            # For TCF we may have too many frames, so we downsample
            # TODO fix
            if len(frames) > 500:
                frames = frames[::5]

            duration = len(frames) / fps  # duration in ms
            _filename = f"{slice_name}_{filename}"

            frames[0].save(
                output_path / _filename,
                save_all=True,
                append_images=frames[1:],
                duration=duration,
                loop=0,
            )
            self._logger.info(f"GIF saved to {_filename}")

    @abstractmethod
    def plot(self, output_path: Path | None = None) -> None:
        """Plot the environments configuration.

        Parameters
        ----------
        output_path: Path | None
            Path to save the plot. If None, the current directory is used. Defaults to
            None.
        """
        raise NotImplementedError

    @property
    @abstractmethod
    def id(self) -> str:
        """Unique identifier for the environment."""
        raise NotImplementedError

    @property
    @abstractmethod
    def initial_domain_id(self) -> str:
        """Unique identifier for the initial domain."""
        raise NotImplementedError

    def _get_domain_dir(self, idx: int) -> Path:
        return fluidgym_config.initial_domains_path / self.initial_domain_id / str(idx)

    def _save_initial_domain(self, mode: EnvMode, idx: int) -> None:
        """Save the initial domain to disk.

        Parameters
        ----------
        mode : EnvMode
            Environment mode ('train', 'val', 'test').

        idx: int
            Index of the initial domain to save.
        """
        out_dir = self._get_domain_dir(idx)
        out_dir.mkdir(parents=True, exist_ok=True)
        save_domain(
            domain=self._domain,
            path=str(out_dir / mode.value),
        )

    def load_initial_domain(self, idx: int, mode: EnvMode | None = None) -> None:
        """Public method to load the initial domain from disk
        using the current mode.

        Parameters
        ----------
        idx: int
            Index of the initial domain to load.

        mode: EnvMode | None
            Environment mode ('train', 'val', 'test'). If None, uses the current mode.
            Defaults to None.
        """
        if mode is None:
            mode = self._mode

        self._domain = self.__load_initial_domain(mode=mode, idx=idx)
        prep_fn = self._get_prep_fn(self._domain)
        self._sim = self._get_simulation(self._domain, prep_fn)

        # Some envs may need additional initialization
        self._additional_initialization()

    def __load_initial_domain(self, mode: EnvMode, idx: int) -> PISOtorch.Domain:
        """Load the initial domain from disk.

        Parameters
        ----------
        mode: EnvMode
            Environment mode ('train', 'val', 'test').

        idx: int
            Index of the initial domain to load.

        Returns
        -------
        PISOtorch.Domain
            The loaded domain.
        """
        out_dir = self._get_domain_dir(idx)
        domain = load_domain(
            path=str(out_dir / mode.value),
            dtype=self._dtype,
            device=self._cuda_device,
            with_scalar=True,
        )
        domain.PrepareSolve()
        return domain

    def init(self) -> None:
        """Generate and save the initial domain if it does not already exist."""
        self._enable_actions = False
        self.__load_domain_on_reset = False

        def save_render(mode: EnvMode, idx: int) -> None:
            self.render(
                save=True,
                filename=f"{mode.value}",
                output_path=fluidgym_config.initial_domains_path
                / self.initial_domain_id
                / str(idx),
            )

        for i in range(N_INITIAL_DOMAINS):
            self._logger.info(f"Generating initial domains {i}")
            for mode_seed, mode in zip(
                MODE_SEEDS,
                [EnvMode.TRAIN, EnvMode.VAL, EnvMode.TEST],
                strict=False,
            ):
                if self._check_initial_domains_exists(mode=mode, idx=i):
                    self._logger.info(
                        f"Initial domain for {mode} with index {i} already exists."
                        f"Skipping generation."
                    )
                    self.load_initial_domain(idx=i, mode=mode)
                    save_render(mode=mode, idx=i)
                    continue

                seed = mode_seed + i

                self.reset(seed=seed)
                self._logger.info(f"Simulating {mode} domain.")

                # For additional randomization, we adapt the number of steps
                n_steps = self._initial_domain_steps + self._np_rng.integers(
                    -int(0.15 * self._initial_domain_steps),
                    int(0.15 * self._initial_domain_steps) + 1,
                )

                for _ in range(n_steps):
                    self.step(self._zero_action)
                self._save_initial_domain(mode=mode, idx=i)
                save_render(mode=mode, idx=i)
                self._logger.info(f"Finished simulating {mode} domain.")

                # For some fields (e.g. the cylinder), we generate the domains
                # by continuing the simulation, so we only need to do this once
                if not self._initial_domain_restart:
                    # Validation
                    for _ in range(int(n_steps * 0.1)):
                        self.step(self._zero_action)
                    self._save_initial_domain(mode=EnvMode.VAL, idx=i)
                    save_render(mode=EnvMode.VAL, idx=i)
                    self._logger.info("Finished simulating val domain.")

                    # Test
                    for _ in range(int(n_steps * 0.1)):
                        self.step(self._zero_action)
                    self._save_initial_domain(mode=EnvMode.TEST, idx=i)
                    save_render(mode=EnvMode.TEST, idx=i)
                    self._logger.info("Finished simulating test domain.")
                    break

        self._enable_actions = True
        self.__load_domain_on_reset = True

    def _save_domain_statistics(self, statistics: dict[str, dict[str, float]]) -> None:
        """Save statistics as a JSON file.

        Parameters
        ----------
        statistics: dict
            The statistics to save.
        """
        save_statistics(
            path=fluidgym_config.initial_domains_path / self.initial_domain_id,
            data=statistics,
        )

    def _load_domain_statistics(self) -> dict[str, dict[str, float]]:
        """Load statistics from a JSON file.

        Returns
        -------
        dict[str, dict[str, float]]
            The loaded statistics.
        """
        stats = load_statistics(
            path=fluidgym_config.initial_domains_path / self.initial_domain_id,
        )

        self._velocity_stats = Stats(**stats["velocity_magnitude"])
        self._pressure_stats = Stats(**stats["pressure"])
        self._metrics_stats = {key: Stats(**stats[key]) for key in self._metrics}

        return stats

    def _save_uncontrolled_episode(
        self, metrics: pd.DataFrame, idx: int, mode: EnvMode
    ) -> None:
        """Save metrics as a CSV file.

        Parameters
        ----------
        statistics: pd.DataFrame
            The metrics to save.

        idx: int
            Index of the initial domain.

        mode : EnvMode
            Environment mode ('train', 'val', 'test').
        """
        save_uncontrolled_episode(
            path=self._get_domain_dir(idx),
            mode_name=mode.value,
            episode_df=metrics,
        )

    def _load_uncontrolled_episode(self, idx: int, mode: EnvMode) -> pd.DataFrame:
        """Load uncontrolled episode metrics for a given initial domain.

        Parameters
        ----------
        idx: int
            Index of the initial domain.

        mode : EnvMode
            Environment mode ('train', 'val', 'test').

        Returns
        -------
        pd.DataFrame
            The loaded metrics.
        """
        return load_uncontrolled_episode(
            path=self._get_domain_dir(idx),
            mode_name=mode.value,
        )

    def get_uncontrolled_episode_metrics(self) -> pd.DataFrame | None:
        """Get the uncontrolled episode metrics for the current domain.

        Note: This method returns the metrics for the currently loaded
        (non-randomized) initial domain. If the environment has been reset
        with randomization, the metrics may not correspond to the current state.

        Returns
        -------
        pd.DataFrame | None
            The uncontrolled episode metrics, or None if not available.
        """
        return self._uncontrolled_episode

    def detach(self) -> None:
        """Detach all tensors in the simulation from the computation graph."""
        self._domain.Detach()

        assert self._domain.viscosity.grad_fn is None
        for b in self._domain.getBlocks():
            assert b.velocity.grad_fn is None
            assert b.velocityGrad.grad_fn is None
            assert b.pressure.grad_fn is None
            assert b.pressureGrad.grad_fn is None

    def plot_grid(self) -> None:
        """Plot the simulation grid."""
        if not hasattr(self, "_domain"):
            raise RuntimeError("Domain is not initialized. Please call reset() first.")

        grids: list[torch.Tensor] = self._domain.getVertexCoordinates()
        if self._ndims == 3:
            grids = [grid[:, :2, 0, :, :] for grid in grids]

        fig, ax = plot_grids(
            grids,
            color=fluidgym_config.palette[: len(grids)],  # type: ignore
            type="pdf",
            linewidth=0.5,
            fig_scale=2,
        )
        ax.grid(True)
        fig.savefig(f"{self.id}_grid.pdf")

    @property
    def action_space(self) -> spaces.Box:
        """The action space of the environment."""
        return self._action_space

    @property
    def observation_space(self) -> spaces.Dict:
        """The observation space of the environment."""
        return self._observation_space

    def get_state(self) -> EnvState:
        """Get the current state of the environment.

        Returns
        -------
        EnvState
            The current state of the environment.
        """
        domain = self._domain.Clone()
        domain.PrepareSolve()
        domain.Detach()

        return EnvState(
            class_name=self.__class__.__name__,
            domain=domain,
            n_steps=self._n_steps,
            mode=self._mode,
            additional_info={},
        )

    def set_state(self, state: EnvState) -> None:
        """Set the current state of the environment.

        Parameters
        ----------
        state: EnvState
            The state to set the environment to.
        """
        if state.class_name != self.__class__.__name__:
            raise ValueError(
                f"State class name {state.class_name} does not match "
                f"environment class name {self.__class__.__name__}."
            )

        self._domain = state.domain.Clone()
        self._domain.PrepareSolve()
        self._sim = self._get_simulation(
            domain=self._domain,
            prep_fn=self._get_prep_fn(self._domain),
        )
        self._n_steps = state.n_steps
        self._mode = state.mode

        self._additional_initialization()
